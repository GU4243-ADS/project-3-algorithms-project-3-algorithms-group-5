png('../figs/male_wordcloud.png')
male_words <- names(table(male_lines$word))
male_freqs <- table(male_lines$word)
wordcloud(male_words, male_freqs, max.words = 50, color = c("purple4", "red4", "black"))
dev.off()
png('../figs/female_wordcloud.png')
female_words <- names(table(female_lines$word))
female_freqs <- table(female_lines$word)
wordcloud(female_words, female_freqs, max.words = 50, color = c("purple4", "red4", "black"))
dev.off()
wordcloud(male_words, male_freqs, max.words = 50, color = c("purple4", "red4", "black"))
wordcloud(female_words, female_freqs, max.words = 50, color = c("purple4", "red4", "black"))
#Finding single/plural pronouns
pronoun_wrd = unnest_tokens(spooky, word, text) %>%
mutate(single = (word == 'he'| word == 'him'| word == 'his'|word =='she' |word == 'her'|word == 'hers' |word =='I'|word =='me'|word =='my'|word=='mine')) %>%
mutate(plural = (word == 'we'|word=='us'|word=='our'|word=='ours'|word=='they'|word=='them'|word=='their'|word=='theirs')) %>%
unite(pronoun, single, plural) %>%
mutate(pronoun = fct_recode(as.factor(pronoun), single = "TRUE_FALSE", plural = "FALSE_TRUE", na = "FALSE_FALSE")) %>%
filter(pronoun != "na")
pronoun_frequency <- count(pronoun_wrd, pronoun, author)
pronoun_tf_idf    <- bind_tf_idf(pronoun_frequency, pronoun, author, n)
ggplot(pronoun_tf_idf) +
geom_col(aes(pronoun, tf, fill = author),position = "dodge") +
labs(x = NULL, y = "TF values") +
theme(legend.position = "top", axis.text.x  = element_text(angle=45, hjust=1, vjust=0.9)) +
labs(title = "Pronoun Frequency(Single/Plural)")
ggsave('pronoun_frequency.png',path='../figs')
#Single/Plural Sentiment Analysis
single_wrd <- pronoun_wrd %>%
group_by(id) %>%
filter(pronoun =='single')
single_groups <- unique(single_wrd[,1])
plural_wrd <- pronoun_wrd %>%
group_by(id) %>%
filter(pronoun =='plural')
plural_groups <- unique(plural_wrd[,1])
single_only <- anti_join(single_groups,plural_groups)
plural_only <- anti_join(plural_groups,single_groups)
single_lines <- spooky %>%
filter(id %in% single_only$id)
plural_lines <- spooky %>%
filter(id %in% plural_only$id)
get_sentiments('nrc')
single_wrd <- unnest_tokens(single_lines, word, text)
plural_wrd <- unnest_tokens(plural_lines, word, text)
single_sentiments <- inner_join(single_wrd, get_sentiments('nrc'), by = "word")
plural_sentiments <- inner_join(plural_wrd, get_sentiments('nrc'), by = "word")
single_sentiment_frequency <- count(single_sentiments, sentiment, author)
single_tf_idf    <- bind_tf_idf(single_sentiment_frequency, sentiment, author, n)
plural_sentiment_frequency <- count(plural_sentiments, sentiment, author)
plural_tf_idf    <- bind_tf_idf(plural_sentiment_frequency, sentiment, author, n)
single_tf_idf$diff <- single_tf_idf$tf-plural_tf_idf$tf
ggplot(single_tf_idf) +
geom_col(aes(sentiment, diff, fill = author),position = "dodge") +
labs(x = NULL, y = "Difference in TF values") +
theme(axis.text.x  = element_text(angle=45, hjust=1, vjust=0.9)) +
labs(title = "Single - Plural Sentiment Frequency Difference")
ggsave('pronoun_sentiments.png',path='../figs')
#Finding light/dark words
lights_wrd = unnest_tokens(spooky, word, text) %>%
mutate(light = (word == 'light'|word =='bright'|word=='luminous'|word=='rich'|word=='shiny'|word=='sunny'|word=='sun'|word=='burnished'|word=='flashing'|word=='glowing'|word=='shining'|word=='radiant'|word=='cloudless'|word=='polished'|word=='lustrous'|word=='white')) %>%
mutate(dark = (word == 'dark'|word=='black'|word=='grey'|word=='gray'|word=='dim'|word=='darkened'|word=='dingy'|word=='dull'|word=='foggy'|word=='gloomy'|word=='shady'|word=='shadow'|word=='somber')) %>%
unite(light, light, dark) %>%
mutate(light = fct_recode(as.factor(light), light = "TRUE_FALSE", dark = "FALSE_TRUE", na = "FALSE_FALSE")) %>%
filter(light != "na")
light_frequency <- count(lights_wrd, light, author)
light_tf_idf    <- bind_tf_idf(light_frequency, light, author, n)
ggplot(light_tf_idf) +
geom_col(aes(light, tf, fill = author),position = "dodge") +
labs(x = NULL, y = "TF values") +
theme(axis.text.x  = element_text(angle=45, hjust=1, vjust=0.9)) +
labs(title = "Light vs Dark Frequency")
ggsave('lights_frequency.png',path='../figs')
#Light and Dark Sentiments
light_wrd <- lights_wrd %>%
group_by(id) %>%
filter(light =='light')
light_groups <- unique(light_wrd[,1])
dark_wrd <- lights_wrd %>%
group_by(id) %>%
filter(light =='dark')
dark_groups <- unique(dark_wrd[,1])
light_only <- anti_join(light_groups,dark_groups)
dark_only <- anti_join(dark_groups,light_groups)
light_lines <- spooky %>%
filter(id %in% light_only$id)
dark_lines <- spooky %>%
filter(id %in% dark_only$id)
get_sentiments('nrc')
light_wrd <- unnest_tokens(light_lines, word, text)
dark_wrd <- unnest_tokens(dark_lines, word, text)
light_sentiments <- inner_join(light_wrd, get_sentiments('nrc'), by = "word")
dark_sentiments <- inner_join(dark_wrd, get_sentiments('nrc'), by = "word")
light_sentiment_frequency <- count(light_sentiments, sentiment, author)
light_tf_idf    <- bind_tf_idf(light_sentiment_frequency, sentiment, author, n)
dark_sentiment_frequency <- count(dark_sentiments, sentiment, author)
dark_tf_idf    <- bind_tf_idf(dark_sentiment_frequency, sentiment, author, n)
light_tf_idf$diff <- light_tf_idf$tf-dark_tf_idf$tf
ggplot(light_tf_idf) +
geom_col(aes(sentiment, diff, fill = author),position = "dodge") +
labs(x = NULL, y = "Difference in TF values") +
theme(axis.text.x  = element_text(angle=45, hjust=1, vjust=0.9)) +
labs(title = "Light - Dark Sentiment Frequency Difference")
ggsave('lights_sentiment.png',path='../figs')
#Light and dark wordcloud, with stopwords removed
spooky_wrd <- unnest_tokens(spooky, word, text)
spooky_wrd <- anti_join(spooky_wrd, stop_words, by = "word")
light_lines <- spooky_wrd %>%
filter(id %in% light_groups$id)
dark_lines <- spooky_wrd %>%
filter(id %in% dark_groups$id)
png('../figs/light_wordcloud.png')
light_words <- names(table(light_lines$word))
light_freqs <- table(light_lines$word)
wordcloud(light_words, light_freqs, max.words = 50, color = c("purple4", "red4", "black"))
dev.off()
png('../figs/dark_wordcloud.png')
dark_words <- names(table(dark_lines$word))
dark_freqs <- table(dark_lines$word)
wordcloud(dark_words, dark_freqs, max.words = 50, color = c("purple4", "red4", "black"))
dev.off()
wordcloud(light_words, light_freqs, max.words = 50, color = c("purple4", "red4", "black"))
wordcloud(dark_words, dark_freqs, max.words = 50, color = c("purple4", "red4", "black"))
packages.used <- c("ggplot2", "dplyr", "tibble", "tidyr",  "stringr", "tidytext", "topicmodels", "wordcloud", "ggridges", "data.table","igraph","ggraph","babynames","alluvial","Matrix","treemapify","ggExtra","caret","xgboost")
# check packages that need to be installed.
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))
# install additional packages
if(length(packages.needed) > 0) {
install.packages(packages.needed, dependencies = TRUE, repos = 'http://cran.us.r-project.org')
}
library(ggplot2);library(dplyr);library(tibble);library(tibble);library(tidyr)
library(stringr);library(tidytext);library(topicmodels);library(wordcloud);library(xgboost)
library(ggridges);library(data.table);library(igraph);library(ggraph);library(babynames)
library(alluvial);library(Matrix);library(treemapify);library(ggExtra);library(caret)
source("../libs/multiplot.R")
get_binCI <- function(x,n) as.list(setNames(binom.test(x,n)$conf.int, c("lwr", "upr")))
spooky <- read.csv('../data/spooky.csv', as.is = TRUE)
spooky$sen_length <- str_length(spooky$text)
# see the sentence length quantile
quantile(spooky$sen_length, c(0.999))
# use data table to cut the data
spooky<-data.table(spooky)
summary(spooky[sen_length>700])
spooky<-spooky[sen_length<=700]
summary(spooky)
# make a training and test set
spooky<-spooky[,-c("sen_length")]
sample<-sample(c(1:19548),13583)
train<-spooky[sample,]
test<-spooky[-sample,]
# get bigram
t2 <- train %>% select(author, text) %>% unnest_tokens(bigram, text, token = "ngrams", n = 2)
# filter out stop words
bi_sep <- t2 %>%
separate(bigram, c("word1", "word2"), sep = " ")
bi_filt <- bi_sep %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
# combine back together
t2 <- bi_filt %>%
unite(bigram, word1, word2, sep = " ")
# calculate frequency
t2_tf_idf <- t2 %>%
count(author, bigram) %>%
bind_tf_idf(bigram, author, n) %>%
arrange(desc(tf_idf))
# plot it
t2_tf_idf %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>%
group_by(author) %>% top_n(10, tf_idf) %>% ungroup() %>%
ggplot(aes(bigram, tf_idf, fill = author)) +
geom_col() + labs(x = NULL, y = "TF-IDF values") +
theme(legend.position = "none") +
facet_wrap(~ author, ncol = 3, scales = "free") +
coord_flip()
t3 <- train %>% select(id, author, text) %>% unnest_tokens(trigram, text, token = "ngrams", n = 3)
tri_sep <- t3 %>%
separate(trigram, c("word1", "word2","word3"), sep = " ")
tri_filt <- tri_sep %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word3 %in% stop_words$word)
# look for 3 word
trigram_counts <- tri_filt %>%
count(word1, word2, word3, sort = TRUE)
# transfer to visualize
trigram_graph <- trigram_counts %>%
filter(n > 2) %>%
graph_from_data_frame()
# create small arrows
a <- grid::arrow(type = "closed", length = unit(.1, "inches"))
# plot the relation between words
ggraph(trigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "lightblue", size = 3) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
# get one word statistics
t1 <- train %>% select(author, text) %>% unnest_tokens(word, text)
# plot percent of positive
t1 %>%
inner_join(get_sentiments("bing"), by = "word") %>%
ggplot(aes(author, fill = sentiment)) +
geom_bar(position = "fill")
# plot the words frequency behind the word not, as (not not)= yes
train %>%
select(author, text) %>% unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ")%>% filter(word1 == "not") %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
count(word1, word2, score, sort = TRUE) %>%
ungroup() %>% mutate(contribution = n * score) %>%
arrange(desc(abs(contribution))) %>% head(15) %>%
mutate(word2 = reorder(word2, contribution)) %>%
ggplot(aes(word2, n * score, fill = n * score > 0)) +
geom_col(show.legend = FALSE) +
xlab("") +
ylab("Sentiment score * number of occurrences") +
coord_flip() +
theme(plot.title = element_text(size=11)) +
ggtitle("All authors - Words preceded by the term 'not'")
# combine train/test for efficient formatting
combine <- spooky
# engineered features (see chapters above)
#------------
t1_stop <- combine %>%
unnest_tokens(word, text) %>%
mutate(stop = word %in% stop_words$word,
name = word %in% str_to_lower(babynames$name)
)
# get sentence length
foo <- t1_stop %>%
group_by(id) %>%
count() %>%
rename(sen_len = n)
# assign a row index, identify if the word is a name
bar <- t1_stop %>%
rownames_to_column() %>%
select(-stop) %>%
distinct(id, word, .keep_all = TRUE) %>%
select(-id, -word) %>%
mutate(dstnct = TRUE)
# sentence has repetition
dst_sent <- t1_stop %>%
rownames_to_column() %>%
left_join(bar, by = "rowname") %>%
replace_na(list(dstnct = FALSE)) %>%
group_by(id, dstnct) %>%
count() %>%
spread(dstnct, n, fill = 0) %>%
mutate(frac_distinct = `TRUE`/(`TRUE`+`FALSE`)*100,
lwr = get_binCI(`TRUE`,(`TRUE`+`FALSE`))[[1]]*100,
upr = get_binCI(`TRUE`,(`TRUE`+`FALSE`))[[2]]*100
) %>%
ungroup() %>%
left_join(foo, by = "id")
# sentence has repetition
foo <- dst_sent %>%
mutate(repetition = !near(frac_distinct, 100)) %>%
select(id, repetition)
# sentence has alliteration
foo2 <- t1_stop %>%
mutate(first = str_sub(word, start = 1, end = 1),
f_lead_1 = lead(first, n = 1),
f_lead_2 = lead(first, n = 2),
id_lead_1 = lead(id, n = 1),
id_lead_2 = lead(id, n = 2),
allit2 = first == f_lead_1 & id == id_lead_1,
allit3 = first == f_lead_1 & first == f_lead_2 & id == id_lead_1 & id == id_lead_2
) %>%
filter(!is.na(allit2)) %>%
group_by(id, allit2) %>%
count() %>%
spread(allit2, n) %>%
mutate(has_allit = !is.na(`TRUE`)) %>%
select(id, has_allit)
# sentence has name
foo3 <- t1_stop %>%
group_by(id, name) %>%
count() %>%
spread(name, n) %>%
mutate(has_name = !is.na(`TRUE`)) %>%
ungroup() %>%
select(id, has_name)
# add has_dialog and join with previous
combine_feat <- combine %>%
mutate(dialog = str_count(text, '\"\"'),
has_dialog = dialog > 0) %>%
select(id, has_dialog) %>%
left_join(foo, by = "id") %>%
left_join(foo2, by = "id") %>%
left_join(foo3, by = "id") %>%
arrange(id)
# Format engineered features to sparse matrix
#------------
target <- train %>%
arrange(id) %>%
select(author) %>%
mutate(author = as.integer(case_when(
author == "MWS" ~ 1,
author == "HPL" ~ 2,
author == "EAP" ~ 3
)))
foo <- combine_feat %>%
select(-id) %>%
mutate_all(as.numeric)
combine_feat2 <- as(object = as.matrix(foo), Class = "dgCMatrix", strict = TRUE)
# Sparse Matrix for DTM
#---------------
t1 <- combine %>% unnest_tokens(word, text)
freq <-t1 %>%
count(id, word)
combine_sparse <- cast_sparse(freq, id, word, n)
#--------------
# Combine DTM and spare engineered features
combine_new <- cBind(combine_feat2, combine_sparse)
# divide back to train and test
sel <- combine_feat$id %in% train$id
train_new <- combine_new[sel,]
test_new <- combine_new[!sel,]
trainIndex <- createDataPartition(target$author, p = 0.8, list = FALSE, times = 1)
trainIndex <- trainIndex[1:nrow(trainIndex)]
dtrain <- xgb.DMatrix(train_new[trainIndex,], label = target$author[trainIndex]-1)
dvalid <- xgb.DMatrix(train_new[-trainIndex,], label = target$author[-trainIndex]-1)
dtest <- xgb.DMatrix(test_new)
# set up some initial values
xgb_params <- list(min_child_weight = 5,
eta = 0.5,
colsample_bytree = 0.9,
max_depth = 6,
subsample = 0.9,
seed = 666,
nthread = -1,
booster = 'gbtree',
eval_metric = "mlogloss",
objective = 'multi:softprob',
num_class = 3
)
xgb_cv <- xgb.cv(nfold = 5,
nrounds = 300,
early_stopping_rounds = 20,
print_every_n = 20,
data = dtrain,
xgb_params)
watchlist <- list(train = dtrain, valid = dvalid)
xgb_fit <- xgb.train(params = xgb_params,
data = dtrain,
print_every_n = 20,
watchlist = watchlist,
nrounds = xgb_cv$best_iteration)
foo <- predict(xgb_fit,dtest, reshape = TRUE, type = 'prob')
pred <- test %>%
arrange(id) %>%
mutate(MWS = foo[,1],
HPL = foo[,2],
EAP = foo[,3]
)
pred <- test %>%
select(id) %>%
left_join(pred, by = "id")
# here we see the prediction values
head(pred)
source("http://bioconductor.org/biocLite.R")
biocLite()
biocLite("EBImage")
library("EBImage")
img <- readImage("pet1.jpg")
print(img)
display(img)
plot(img)
n_r <- n_c <- 100
M <- matrix(img[101:(100 + n_r), 51:(50 + n_r), ], n_r, n_c)
MM <- M[,rev(1:ncol(M))]
par(mfrow=c(1,2))
image(x=1:n_r, y=1:n_c, z=M, axes = FALSE, xlab="", ylab="", col = grey(seq(0, 1, length = 256)))
image(x=1:n_r, y=1:n_c, z=MM, axes = FALSE, xlab="", ylab="", col = grey(seq(0, 1, length = 256)))
par(mfrow=c(1,1))
img_zip <- Image(M, dim=c(n_r, n_c))
plot(img_zip)
str(img)
dim(img)
imageData(img)[1:3, 1:6,]
hist(img)
img_small <- resize(img, 128, 128)
display(img_small)
img_dog <- readImage("pet2.jpg")
img_dog <- resize(img_dog, 128, 128)
img_all <- EBImage::combine(img_small, img_dog)
display(img_all, all=TRUE)
img_all2 <- EBImage::combine(img_small, flip(img_small), flop(img_small))
display(img_all2, all=TRUE)
library(reticulate)
# If you are using anaconda, point reticulate to the correct conda environment
# use_condaenv('your-environment')
# for some reason I need to import cv2 and tensorflow before EBImage
# or everything breaks.
cv2 <- reticulate::import('cv2')
library(EBImage)
# This imports the cv2 package.
cv2 <- reticulate::import('cv2')
img <- cv2$imread('pet1.jpg') / 255
img_leaf <- cv2$imread('leaf.png') / 255
img_r <- EBImage::Image(aperm(img, c(2, 1, 3)), colormode = 'Color')
plot(img_r)
to_ebimage <- function(img) {
EBImage::Image(aperm(img, c(2, 1, 3)), colormode = 'Color')
}
laplacian <- cv2$Laplacian(img, cv2$CV_64F)
plot(to_ebimage(laplacian))
sobel_x <- cv2$Sobel(img, cv2$CV_64F, 1L, 0L)
sobel_y <- cv2$Sobel(img, cv2$CV_64F, 0L, 1L)
plot(to_ebimage(sobel_x))
plot(to_ebimage(sobel_y))
# We create a HOG object
# The only parameter of real importance here is winSize,
# but we are required to pass in at least this many parameters
# so that OpenCV can figure out which function we want to call.
winSize <- tuple(64L,64L)
blockSize <- tuple(16L,16L)
blockStride <- tuple(8L,8L)
cellSize <- tuple(8L,8L)
nbins = 9L
hog = cv2$HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins)
img_resized <- cv2$resize(img, dsize=tuple(64L, 64L))
hog_values <- hog$compute(np_array(img_resized * 255, dtype='uint8'))
img_gray <- cv2$cvtColor(np_array(img, dtype='float32'), cv2$COLOR_BGR2GRAY)
sift <- cv2$xfeatures2d$SIFT_create()
img_gray_uint8 <- np_array(img_gray * 255, dtype='uint8')
keypoints <- sift$detect(img_gray_uint8, NULL)
img_keypoints <- cv2$drawKeypoints(img_gray_uint8,
keypoints, NULL,
flags=cv2$DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
plot(to_ebimage(img_keypoints / 255))
keypoints_and_values <- sift$compute(img_gray_uint8, keypoints)
values <- keypoints_and_values[[2]]
dim(values)
keypoints_dense <- apply(as.matrix(expand.grid(1:8, 1:8)), 1, function (x) {
cv2$KeyPoint((x[1] - 0.5) * 16, (x[2] - 0.5) * 16, 16)
})
img_gray_resized <- cv2$cvtColor(np_array(img_resized, dtype='float32'),
cv2$COLOR_BGR2GRAY)
img_gray_resized_uint8 <- np_array(img_gray_resized * 255, dtype='uint8')
img_keypoints_dense <- cv2$drawKeypoints(
img_gray_resized_uint8, keypoints_dense, NULL,
flags=cv2$DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
plot(to_ebimage(img_keypoints_dense / 255))
res_dense <- sift$compute(img_gray_resized_uint8, keypoints_dense)
values_dense <- res_dense[[2]]
dim(values_dense)
setwd("~/Projects/STAT4243/Project3/project-3-algorithms-project-3-algorithms-group-5/doc")
library(tidyverse)
source("../lib/functions.R")
MS_train_dir <- "../data/Proj3_Data/MS_sample/data_train.csv"
MS_test_dir <- "../data/Proj3_Data/MS_sample/data_test.csv"
EM_train_dir <- "../data/Proj3_Data/MS_sample/data_train.csv"
EM_test_dir <- "../data/Proj3_Data/MS_sample/data_test.csv"
MS_train <- read.csv(MS_train_dir, as.is = TRUE, header = TRUE)
MS_train <- MS_train[, 2:4]
MS_UI_matrix <- MS_data_transform(MS_train)
save(MS_UI, file = "../output/MS_UI.RData")
MS_train <- read.csv(MS_train_dir, as.is = TRUE, header = TRUE)
MS_train <- MS_train[, 2:4]
MS_UI_matrix <- MS_data_transform(MS_train)
View(MS_UI_matrix)
save(MS_UI_matrix, file = "../output/MS_UI.RData")
MS_train <- read.csv(MS_train_dir, as.is = TRUE, header = TRUE)
MS_train <- MS_train[, 2:4]
MS_UI_matrix <- MS_data_transform(MS_train)
save(MS_UI_matrix, file = "../output/MS_UI.RData")
EM_train <- read.csv(EM_train_dir, as.is = TRUE, header = TRUE)
EM_train <- EM_train[, 2:4]
EM_UI_matrix <- movie_data_transform(EM_train)
MS_train <- read.csv(MS_train_dir, as.is = TRUE, header = TRUE)
MS_train <- MS_train[, 2:4]
MS_UI_matrix <- MS_data_transform(MS_train)
library(tidyverse)
source("../lib/functions.R")
MS_train_dir <- "../data/Proj3_Data/MS_sample/data_train.csv"
MS_test_dir <- "../data/Proj3_Data/MS_sample/data_test.csv"
EM_train_dir <- "../data/Proj3_Data/eachmovie_sample/data_train.csv"
EM_test_dir <- "../data/Proj3_Data/eachmovie_sample/data_test.csv"
MS_train <- read.csv(MS_train_dir, as.is = TRUE, header = TRUE)
MS_train <- MS_train[, 2:4]
MS_UI_matrix <- MS_data_transform(MS_train)
save(MS_UI_matrix, file = "../output/MS_UI.RData")
EM_train <- read.csv(EM_train_dir, as.is = TRUE, header = TRUE)
EM_train <- EM_train[, 2:4]
EM_UI_matrix <- movie_data_transform(EM_train)
save(EM_UI_matrix, file = "../output/EM_UI.RData")
### EM ratings is in scale of 5. Create a normalized matrix in scale of 1 for Mean-squared difference sim weights calculation.
EM_UI_matrix_n <- EM_UI_matrix / 5
tm_pearson_EM <- NA
tm_spearman_EM <- NA
tm_cosine_EM <- NA
tm_entropy_EM <- NA
tm_msd_EM <- NA
tm_pearson_EM <- system.time(EM_sim_pearson <- calc_weight(EM_UI_matrix, method = 'pearson'))
tm_spearman_EM <- system.time(EM_sim_spearman <- calc_weight(EM_UI_matrix, method = 'spearman'))
tm_cosine_EM <- system.time(EM_sim_cosine <- calc_weight(EM_UI_matrix, method = 'cosine'))
tm_pearson_EM <- NA
tm_spearman_EM <- NA
tm_cosine_EM <- NA
tm_entropy_EM <- NA
tm_msd_EM <- NA
tm_pearson_EM <- system.time(EM_sim_pearson <- calc_weight(EM_UI_matrix, method = 'pearson'))
#tm_spearman_EM <- system.time(EM_sim_spearman <- calc_weight(EM_UI_matrix, method = 'spearman'))
tm_cosine_EM <- system.time(EM_sim_cosine <- calc_weight(EM_UI_matrix, method = 'cosine'))
tm_entropy_EM <- system.time(EM_sim_entropy <- calc_weight(EM_UI_matrix, method = 'entropy'))
summary(EM_sim_pearson)
head(EM_sim_pearson)
tm_entropy_EM <- system.time(EM_sim_entropy <- calc_weight(EM_UI_matrix, method = 'entropy'))
tm_entropy_EM <- system.time(EM_sim_entropy <- calc_weight(EM_UI_matrix, method = 'entropy'))
