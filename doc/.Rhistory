# Format engineered features to sparse matrix
#------------
target <- train %>%
arrange(id) %>%
select(author) %>%
mutate(author = as.integer(case_when(
author == "MWS" ~ 1,
author == "HPL" ~ 2,
author == "EAP" ~ 3
)))
foo <- combine_feat %>%
select(-id) %>%
mutate_all(as.numeric)
combine_feat2 <- as(object = as.matrix(foo), Class = "dgCMatrix", strict = TRUE)
# Sparse Matrix for DTM
#---------------
t1 <- combine %>% unnest_tokens(word, text)
freq <-t1 %>%
count(id, word)
combine_sparse <- cast_sparse(freq, id, word, n)
#--------------
# Combine DTM and spare engineered features
combine_new <- cBind(combine_feat2, combine_sparse)
# divide back to train and test
sel <- combine_feat$id %in% train$id
train_new <- combine_new[sel,]
test_new <- combine_new[!sel,]
trainIndex <- createDataPartition(target$author, p = 0.8, list = FALSE, times = 1)
trainIndex <- trainIndex[1:nrow(trainIndex)]
dtrain <- xgb.DMatrix(train_new[trainIndex,], label = target$author[trainIndex]-1)
dvalid <- xgb.DMatrix(train_new[-trainIndex,], label = target$author[-trainIndex]-1)
dtest <- xgb.DMatrix(test_new)
# set up some initial values
xgb_params <- list(min_child_weight = 5,
eta = 0.5,
colsample_bytree = 0.9,
max_depth = 6,
subsample = 0.9,
seed = 666,
nthread = -1,
booster = 'gbtree',
eval_metric = "mlogloss",
objective = 'multi:softprob',
num_class = 3
)
xgb_cv <- xgb.cv(nfold = 5,
nrounds = 300,
early_stopping_rounds = 20,
print_every_n = 20,
data = dtrain,
xgb_params)
watchlist <- list(train = dtrain, valid = dvalid)
xgb_fit <- xgb.train(params = xgb_params,
data = dtrain,
print_every_n = 20,
watchlist = watchlist,
nrounds = xgb_cv$best_iteration)
foo <- predict(xgb_fit,dtest, reshape = TRUE, type = 'prob')
pred <- test %>%
arrange(id) %>%
mutate(MWS = foo[,1],
HPL = foo[,2],
EAP = foo[,3]
)
pred <- test %>%
select(id) %>%
left_join(pred, by = "id")
# here we see the prediction values
head(pred)
source("http://bioconductor.org/biocLite.R")
biocLite()
biocLite("EBImage")
library("EBImage")
img <- readImage("pet1.jpg")
print(img)
display(img)
plot(img)
n_r <- n_c <- 100
M <- matrix(img[101:(100 + n_r), 51:(50 + n_r), ], n_r, n_c)
MM <- M[,rev(1:ncol(M))]
par(mfrow=c(1,2))
image(x=1:n_r, y=1:n_c, z=M, axes = FALSE, xlab="", ylab="", col = grey(seq(0, 1, length = 256)))
image(x=1:n_r, y=1:n_c, z=MM, axes = FALSE, xlab="", ylab="", col = grey(seq(0, 1, length = 256)))
par(mfrow=c(1,1))
img_zip <- Image(M, dim=c(n_r, n_c))
plot(img_zip)
str(img)
dim(img)
imageData(img)[1:3, 1:6,]
hist(img)
img_small <- resize(img, 128, 128)
display(img_small)
img_dog <- readImage("pet2.jpg")
img_dog <- resize(img_dog, 128, 128)
img_all <- EBImage::combine(img_small, img_dog)
display(img_all, all=TRUE)
img_all2 <- EBImage::combine(img_small, flip(img_small), flop(img_small))
display(img_all2, all=TRUE)
library(reticulate)
# If you are using anaconda, point reticulate to the correct conda environment
# use_condaenv('your-environment')
# for some reason I need to import cv2 and tensorflow before EBImage
# or everything breaks.
cv2 <- reticulate::import('cv2')
library(EBImage)
# This imports the cv2 package.
cv2 <- reticulate::import('cv2')
img <- cv2$imread('pet1.jpg') / 255
img_leaf <- cv2$imread('leaf.png') / 255
img_r <- EBImage::Image(aperm(img, c(2, 1, 3)), colormode = 'Color')
plot(img_r)
to_ebimage <- function(img) {
EBImage::Image(aperm(img, c(2, 1, 3)), colormode = 'Color')
}
laplacian <- cv2$Laplacian(img, cv2$CV_64F)
plot(to_ebimage(laplacian))
sobel_x <- cv2$Sobel(img, cv2$CV_64F, 1L, 0L)
sobel_y <- cv2$Sobel(img, cv2$CV_64F, 0L, 1L)
plot(to_ebimage(sobel_x))
plot(to_ebimage(sobel_y))
# We create a HOG object
# The only parameter of real importance here is winSize,
# but we are required to pass in at least this many parameters
# so that OpenCV can figure out which function we want to call.
winSize <- tuple(64L,64L)
blockSize <- tuple(16L,16L)
blockStride <- tuple(8L,8L)
cellSize <- tuple(8L,8L)
nbins = 9L
hog = cv2$HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins)
img_resized <- cv2$resize(img, dsize=tuple(64L, 64L))
hog_values <- hog$compute(np_array(img_resized * 255, dtype='uint8'))
img_gray <- cv2$cvtColor(np_array(img, dtype='float32'), cv2$COLOR_BGR2GRAY)
sift <- cv2$xfeatures2d$SIFT_create()
img_gray_uint8 <- np_array(img_gray * 255, dtype='uint8')
keypoints <- sift$detect(img_gray_uint8, NULL)
img_keypoints <- cv2$drawKeypoints(img_gray_uint8,
keypoints, NULL,
flags=cv2$DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
plot(to_ebimage(img_keypoints / 255))
keypoints_and_values <- sift$compute(img_gray_uint8, keypoints)
values <- keypoints_and_values[[2]]
dim(values)
keypoints_dense <- apply(as.matrix(expand.grid(1:8, 1:8)), 1, function (x) {
cv2$KeyPoint((x[1] - 0.5) * 16, (x[2] - 0.5) * 16, 16)
})
img_gray_resized <- cv2$cvtColor(np_array(img_resized, dtype='float32'),
cv2$COLOR_BGR2GRAY)
img_gray_resized_uint8 <- np_array(img_gray_resized * 255, dtype='uint8')
img_keypoints_dense <- cv2$drawKeypoints(
img_gray_resized_uint8, keypoints_dense, NULL,
flags=cv2$DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
plot(to_ebimage(img_keypoints_dense / 255))
res_dense <- sift$compute(img_gray_resized_uint8, keypoints_dense)
values_dense <- res_dense[[2]]
dim(values_dense)
setwd("~/Projects/STAT4243/Project3/project-3-algorithms-project-3-algorithms-group-5/doc")
library(tidyverse)
source("../lib/functions.R")
MS_train_dir <- "../data/Proj3_Data/MS_sample/data_train.csv"
MS_test_dir <- "../data/Proj3_Data/MS_sample/data_test.csv"
EM_train_dir <- "../data/Proj3_Data/MS_sample/data_train.csv"
EM_test_dir <- "../data/Proj3_Data/MS_sample/data_test.csv"
MS_train <- read.csv(MS_train_dir, as.is = TRUE, header = TRUE)
MS_train <- MS_train[, 2:4]
MS_UI_matrix <- MS_data_transform(MS_train)
save(MS_UI, file = "../output/MS_UI.RData")
MS_train <- read.csv(MS_train_dir, as.is = TRUE, header = TRUE)
MS_train <- MS_train[, 2:4]
MS_UI_matrix <- MS_data_transform(MS_train)
View(MS_UI_matrix)
save(MS_UI_matrix, file = "../output/MS_UI.RData")
MS_train <- read.csv(MS_train_dir, as.is = TRUE, header = TRUE)
MS_train <- MS_train[, 2:4]
MS_UI_matrix <- MS_data_transform(MS_train)
save(MS_UI_matrix, file = "../output/MS_UI.RData")
EM_train <- read.csv(EM_train_dir, as.is = TRUE, header = TRUE)
EM_train <- EM_train[, 2:4]
EM_UI_matrix <- movie_data_transform(EM_train)
MS_train <- read.csv(MS_train_dir, as.is = TRUE, header = TRUE)
MS_train <- MS_train[, 2:4]
MS_UI_matrix <- MS_data_transform(MS_train)
library(tidyverse)
source("../lib/functions.R")
MS_train_dir <- "../data/Proj3_Data/MS_sample/data_train.csv"
MS_test_dir <- "../data/Proj3_Data/MS_sample/data_test.csv"
EM_train_dir <- "../data/Proj3_Data/eachmovie_sample/data_train.csv"
EM_test_dir <- "../data/Proj3_Data/eachmovie_sample/data_test.csv"
MS_train <- read.csv(MS_train_dir, as.is = TRUE, header = TRUE)
MS_train <- MS_train[, 2:4]
MS_UI_matrix <- MS_data_transform(MS_train)
save(MS_UI_matrix, file = "../output/MS_UI.RData")
EM_train <- read.csv(EM_train_dir, as.is = TRUE, header = TRUE)
EM_train <- EM_train[, 2:4]
EM_UI_matrix <- movie_data_transform(EM_train)
save(EM_UI_matrix, file = "../output/EM_UI.RData")
### EM ratings is in scale of 5. Create a normalized matrix in scale of 1 for Mean-squared difference sim weights calculation.
EM_UI_matrix_n <- EM_UI_matrix / 5
tm_pearson_EM <- NA
tm_spearman_EM <- NA
tm_cosine_EM <- NA
tm_entropy_EM <- NA
tm_msd_EM <- NA
tm_pearson_EM <- system.time(EM_sim_pearson <- calc_weight(EM_UI_matrix, method = 'pearson'))
tm_spearman_EM <- system.time(EM_sim_spearman <- calc_weight(EM_UI_matrix, method = 'spearman'))
tm_cosine_EM <- system.time(EM_sim_cosine <- calc_weight(EM_UI_matrix, method = 'cosine'))
tm_pearson_EM <- NA
tm_spearman_EM <- NA
tm_cosine_EM <- NA
tm_entropy_EM <- NA
tm_msd_EM <- NA
tm_pearson_EM <- system.time(EM_sim_pearson <- calc_weight(EM_UI_matrix, method = 'pearson'))
#tm_spearman_EM <- system.time(EM_sim_spearman <- calc_weight(EM_UI_matrix, method = 'spearman'))
tm_cosine_EM <- system.time(EM_sim_cosine <- calc_weight(EM_UI_matrix, method = 'cosine'))
tm_entropy_EM <- system.time(EM_sim_entropy <- calc_weight(EM_UI_matrix, method = 'entropy'))
summary(EM_sim_pearson)
head(EM_sim_pearson)
tm_entropy_EM <- system.time(EM_sim_entropy <- calc_weight(EM_UI_matrix, method = 'entropy'))
tm_entropy_EM <- system.time(EM_sim_entropy <- calc_weight(EM_UI_matrix, method = 'entropy'))
library(tidyverse)
library(tidyverse)
source("../lib/functions.R")
tm_pearson_EM <- NA
tm_spearman_EM <- NA
tm_cosine_EM <- NA
tm_entropy_EM <- NA
tm_msd_EM <- NA
tm_cosine_MS <- system.time(MS_sim_cosine <- calc_weight(MS_UI_matrix, method = 'cosine'))
save(MS_sim_cosine, file = "../output/MS_sim_cosine.RData")
time.taken
colnames(MS_EM_pred_9) <- colnames(MS_UI)
rownames(MS_EM_pred_9) <- rownames(MS_UI)
rownames(MS_EM_pred_9) <- rownames(MS_UI_matrix)
load("/Users/miezai/Documents/GitHub/project-3-algorithms-project-3-algorithms-group-5/data/MS_EM_pred_9.RData")
load("/Users/miezai/Documents/GitHub/project-3-algorithms-project-3-algorithms-group-5 copy/data/MS_pred.RData")
View(MS_pred)
source("../lib/evaluation.R")
pred <- MS_pred
test <- MS_test
MS_UI_test <- load("/Users/miezai/Documents/GitHub/project-3-algorithms-project-3-algorithms-group-5 copy/data/MS_UI_test.RData")
load("/Users/miezai/Documents/GitHub/Spring2018/Project_Starter_Codes/Project3-Algorithms/data/MS_sample/MS_test.RData")
MS_UI_test <- load("/Users/miezai/Documents/GitHub/project-3-algorithms-project-3-algorithms-group-5 copy/data/MS_test.RData")
test <- MS_test
rank(pred, test)
View(pred)
sorted <- rank(pred, test)
pred <- MS_pred
test <- MS_test
View(pred)
View(test)
sorted <- rank(pred, test)
matrix_ranks <- matrix(NA)
for (i in 1:ncol(test)){
rank_pred <- pred[,i] %>% as.data.frame()
rank_pred <- rank_pred %>% mutate(id = row.names(rank_pred)) %>% arrange(desc(.)) %>% mutate(rank = 1:nrow(rank_pred))
rank_test_by_pred <- test[,i] %>% as.data.frame()
rank_test_by_pred <- rank_test_by_pred %>% mutate(id = row.names(rank_test_by_pred))
names(rank_test_by_pred) <- c("test","id")
all <- merge(rank_pred, rank_test_by_pred)
all <- all %>% arrange(rank) %>% select(test)
names(all) <- i
matrix_ranks <- cbind(matrix_ranks,all)
}
View(matrix_ranks)
matrix_ranks <- matrix_ranks[-1]
sorted <- ranks(pred, test)
View(sorted)
View(rank_pred)
rank_pred <- pred[i,] %>% as.data.frame()
View(rank_pred)
View(test)
rank_pred <- pred[i,] %>% as.data.frame()
rank_pred <- rank_pred %>% mutate(id = row.names(rank_pred)) %>% arrange(desc(.)) %>% mutate(rank = 1:nrow(rank_pred))
View(rank_pred)
rank_test_by_pred <- test[iï¼Œ] %>% as.data.frame()
rank_test_by_pred <- test[i,] %>% as.data.frame()
rank_test_by_pred <- rank_test_by_pred %>% mutate(id = row.names(rank_test_by_pred))
View(rank_test_by_pred)
names(rank_test_by_pred) <- c("test","id")
all <- merge(rank_pred, rank_test_by_pred)
all <- all %>% arrange(rank) %>% select(test)
View(all)
all <- merge(rank_pred, rank_test_by_pred)
View(all)
View(test)
all <- all %>% arrange(rank) %>% select(test)
matrix_ranks <- rbind(matrix_ranks,all)
matrix_ranks <- matrix(NA)
matrix_ranks <- rbind(matrix_ranks,all)
matrix_ranks[,i] <- all
matrix_ranks[i,] <- all
matrix_ranks <- matrix(NA,nrow(test),ncol(test))
matrix_ranks[i,] <- all
View(matrix_ranks)
matrix_ranks[i,] <- unname(all)
matrix_ranks[i,] <- unlist(unname(all))
rank_scoring(pred, test, 5)
source("../lib/evaluation.R")
rank_scoring(pred, test, 5)
load("/Users/miezai/Documents/GitHub/project-3-algorithms-project-3-algorithms-group-5/data/MS_EM_pred_9.RData")
load("/Users/miezai/Documents/GitHub/project-3-algorithms-project-3-algorithms-group-5/data/MS_EM_pred_9.RData")
load("/Users/miezai/Documents/GitHub/project-3-algorithms-project-3-algorithms-group-5 copy/data.RData")
load("/Users/miezai/Documents/GitHub/project-3-algorithms-project-3-algorithms-group-5/data.RData")
load("/Users/miezai/Documents/GitHub/project-3-algorithms-project-3-algorithms-group-5/data/MS_EM_pred_9.RData")
colnames(MS_EM_pred_9) <- colnames(MS_UI_matrix)
rownames(MS_EM_pred_9) <- rownames(MS_UI_matrix)
pred <- MS_EM_pred_9
rank_scoring(pred, test, 5)
load("/Users/miezai/Documents/GitHub/project-3-algorithms-project-3-algorithms-group-5/data/MS_pred_cosine.RData")
pred <- MS_pred_cosine
rank_scoring(pred, test, 5)
test_ind <- apply(test, 1, function(rrr){return(which(rrr==1))})
View(test_ind)
function(rrr){return(which(rrr==1))}
rrr
View(test)
View(test_ind)
cols_to_test <- which(test==1)
check_test <- apply(test, 1, to_test )
to_test <- function(test){
which(test == 1)
}
check_test <- apply(test, 1, to_test)
View(check_test)
rank_scoring <- function(pred, test, a){
to_test <- function(test){
which(test == 1)
}
check_test <- apply(test, 1, to_test)
ord <- t(apply(pred, 1, function(rrr){return(order(rrr,decreasing = T))}))
R_a_s <- rep(NA, nrow(test))
R_a_max <- rep(NA, nrow(test))
for(a in 1:nrow(test)){
d<-mean(pred[a,])
j<-ord[a,]
m<-ifelse((pred[a,]-d)>0,(pred[a,]-d),0)
R_a_s[a] <- sum( m / 2^((j-1)/(alpha-1)) )
R_a_max[a] <- length(check_test[[a]])
}
# Final rank score for an experiment
R <- sum(R_a_s) / sum(R_a_max)*100
return(R)
}
rank_scoring <- function(pred, test, a){
to_test <- function(test){
which(test == 1)
}
check_test <- apply(test, 1, to_test)
ord <- t(apply(pred, 1, function(rrr){return(order(rrr,decreasing = T))}))
R_a_s <- rep(NA, nrow(test))
R_a_max <- rep(NA, nrow(test))
for(a in 1:nrow(test)){
d<-mean(pred[a,])
j<-ord[a,]
m<-ifelse((pred[a,]-d)>0,(pred[a,]-d),0)
R_a_s[a] <- sum( m / 2^((j-1)/(alpha-1)) )
R_a_max[a] <- length(check_test[[a]])
}
R <- sum(R_a_s) / sum(R_a_max)*100
return(R)
}
rank_scorin <- function(pred, test, a){
to_test <- function(test){
which(test == 1)
}
check_test <- apply(test, 1, to_test)
ord <- t(apply(pred, 1, function(rrr){return(order(rrr,decreasing = T))}))
R_a_s <- rep(NA, nrow(test))
R_a_max <- rep(NA, nrow(test))
for(a in 1:nrow(test)){
d<-mean(pred[a,])
j<-ord[a,]
m<-ifelse((pred[a,]-d)>0,(pred[a,]-d),0)
R_a_s[a] <- sum( m / 2^((j-1)/(alpha-1)) )
R_a_max[a] <- length(check_test[[a]])
}
R <- sum(R_a_s) / sum(R_a_max)*100
return(R)
}
rank_scorin(pred, test, 5)
rank_scorin <- function(pred, test, a){
to_test <- function(test){
which(test == 1)
}
check_test <- apply(test, 1, to_test)
ord <- t(apply(pred, 1, function(rrr){return(order(rrr,decreasing = T))}))
R_a_s <- rep(NA, nrow(test))
R_a_max <- rep(NA, nrow(test))
for(a in 1:nrow(test)){
d<-mean(pred[a,])
j<-ord[a,]
m<-ifelse((pred[a,]-d)>0,(pred[a,]-d),0)
R_a_s[a] <- sum( m / 2^((j-1)/(a-1)) )
R_a_max[a] <- length(check_test[[a]])
}
R <- sum(R_a_s) / sum(R_a_max)*100
return(R)
}
rank_scoring <- function(pred, test, a){
to_test <- function(test){
which(test == 1)
}
check_test <- apply(test, 1, to_test)
ord <- t(apply(pred, 1, function(rrr){return(order(rrr,decreasing = T))}))
R_a_s <- rep(NA, nrow(test))
R_a_max <- rep(NA, nrow(test))
for(a in 1:nrow(test)){
d<-mean(pred[a,])
j<-ord[a,]
m<-ifelse((pred[a,]-d)>0,(pred[a,]-d),0)
R_a_s[a] <- sum( m / 2^((j-1)/(a-1)) )
R_a_max[a] <- length(check_test[[a]])
}
R <- sum(R_a_s) / sum(R_a_max)*100
return(R)
}
rank_scorin(pred, test, 5)
rank_scorin(pred, test, 5)
rank_scorin <- function(pred, test, a){
to_test <- function(test){
which(test == 1)
}
check_test <- apply(test, 1, to_test)
ord <- t(apply(pred, 1, function(rrr){return(order(rrr,decreasing = T))}))
R_a_s <- rep(NA, nrow(test))
R_a_max <- rep(NA, nrow(test))
for(a in 1:nrow(test)){
d<-mean(pred[a,])
j<-ord[a,]
m<-ifelse((pred[a,]-d)>0,(pred[a,]-d),0)
R_a_s[a] <- sum( m / 2^((j-1)/(a-1)) )
R_a_max[a] <- length(check_test[[a]])
}
R <- sum(R_a_s) / sum(R_a_max)*100
return(R)
}
rank_scoring(pred, test, 5)
rank_scoring(pred, test, 5)
pred <- MS_pred_cosine
test <- MS_test
rank_scoring(pred, test, 5)
source("../lib/evaluation.R")
rank_scoring(pred, test, 5)
rank_scoring <- function(pred, test, a){
visited_ind <- apply(test, 1, function(rrr){return(which(rrr==1))})
ord <- t(apply(predicted, 1, function(rrr){return(order(rrr,decreasing = T))})) #rank list of predicted
# R_a_s: Expected utility of a ranked list for user a
R_a_s <- rep(NA, nrow(web_mini_test))
R_a_max <- rep(NA, nrow(web_mini_test))
for(a in 1:nrow(web_mini_test)){
d<-mean(predicted[a,])
j<-ord[a,] # rank of test case in predicted
m<-ifelse((predicted[a,]-d)>0,(predicted[a,]-d),0)
R_a_s[a] <- sum( m / 2^((j-1)/(alpha-1)) )
R_a_max[a] <- length(visited_ind[[a]])
}
# Final rank score for an experiment
R <- sum(R_a_s) / sum(R_a_max)*100
return(R)
}
source("../lib/evaluation.R")
rank_scorin <- function(pred, test, a){
to_test <- function(test){
which(test == 1)
}
check_test <- apply(test, 1, to_test)
ord <- t(apply(pred, 1, function(rrr){return(order(rrr,decreasing = T))}))
R_a_s <- rep(NA, nrow(test))
R_a_max <- rep(NA, nrow(test))
for(a in 1:nrow(test)){
d<-mean(pred[a,])
j<-ord[a,]
m<-ifelse((pred[a,]-d)>0,(pred[a,]-d),0)
R_a_s[a] <- sum( m / 2^((j-1)/(a-1)) )
R_a_max[a] <- length(check_test[[a]])
}
R <- sum(R_a_s) / sum(R_a_max)*100
return(R)
}
rank_scoring(pred, test, 5)
source("../lib/evaluation.R")
rank_scoring(pred, test, 5)
source("../lib/evaluation.R")
rank_scoring(pred, test, 5)
pred <- MS_EM_pred_9
test <- MS_test
rank_scoring(pred, test, 5)
source("../lib/evaluation.R")
rank_scoring(pred, test, 5)
source("../lib/evaluation.R")
rank_scoring(pred, test, 5)
source("../lib/evaluation.R")
rank_scoring(pred, test, 5)
source("../lib/evaluation.R")
source("../lib/evaluation.R")
rank_scoring(pred, test, 5)
order(pred, decreasing = T)
source("../lib/evaluation.R")
rank_scoring(pred, test, 5)
rank_scoring(pred, test, 5)
source("../lib/evaluation.R")
rank_scoring(pred, test, 5)
order(pred ,decreasing = TRUE)
lib
source("../lib/evaluation.R")
rank_scoring(pred, test, 5)
rank_scoring(pred, test, 5)
source("../lib/evaluation.R")
rank_scoring(pred, test, 5)
source("../lib/evaluation.R")
rank_scoring(pred, test, 5)
rank_scorin(pred, test, 5)
